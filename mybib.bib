% Encoding: ISO-8859-1

@STRING{aes = {Proc. Audio Eng. Soc. Convention}}

@STRING{aescaas = {Proc. {AES} Intl. Conf. on Audio, Acoustics \& Small Spaces}}

@STRING{asha = {Proc. American Speech-Language-Hearing Association Convention}}

@STRING{asilomar = {Proc. Asilomar Conf. on Signals, Systems and Computers}}

@STRING{at = {Annales des T{\'{e}}l{\'{e}}communications}}

@STRING{audiology = {Audiology}}

@STRING{autom = {Automatica}}

@STRING{canece = {Canadian Conf. on Electrical and Computer Engineering}}

@STRING{caracas = {Proc. Intl. Caracas Conf. on Devices, Circuits and Systems}}

@STRING{APSIPA = {Sig. and Inf. Proces. Assoc. An. Sum.t and Conf. (APSIPA), Asia-Pacific}}

@STRING{ciss = {Conf. on Information Sciences and Systems ({CISS})}}

@STRING{clin_neuro = {Clinical Neurophysiology}}

@STRING{cmj = {Computer Music Journal}}

@STRING{dafx = {Proc. Conf. on Digital Audio Effects}}

@STRING{digiece = {Proc. Digest of Intl. Electrical and Electronics Conf. and Exposition}}

@STRING{el = {Electronics Letters}}

@STRING{eurasip_j_adsp = {{EURASIP} Journal on Advances in Signal Processing}}

@STRING{eurasip_j_asp = {{EURASIP} Journal on Applied Signal Processing}}

@STRING{eurospeech = {Proc. European Conf. on Speech Communication and Technology}}

@STRING{eusipco = {Proc. European Signal Processing Conf. (EUSIPCO)}}

@STRING{folia_phon = {Folia Phoniatrica}}

@STRING{geophys = {Geophysics}}

@STRING{iacoust = {Proc. Institute of Acoustics}}

@STRING{ica = {Proc. ICA}}

@STRING{icassp = {Proc. {IEEE} Intl. Conf. on Acoustics, Speech and Signal Processing
	(ICASSP)}}

@STRING{icc = {Proc. Intl. Conf. Commun. ({ICC})}}

@STRING{icct = {Proc. Intl. Conf. on Communications Technology}}

@STRING{icet = {Proc. Intl. Conf. on Emerging Technologies}}

@STRING{icip = {Proc. Intl. Conf. Image Processing}}

@STRING{icisip = {Proc. Intl. Conf. on Intelligent Sensing and Information Processing}}

@STRING{icma = {Proc Intl Conf on Mechatronics and Automation ({ICMA})}}

@STRING{icme = {Proc. Intl. Conf. Multimedia and Expo ({ICME})}}

@STRING{icml = {Proc. Intl. Conf. Machine Learning ({ICML})}}

@STRING{icslp = {Proc. Intl. Conf. on Spoken Lang. Processing ({ICSLP})}}

@STRING{icsp = {Proc. Intl. Conf. on Signal Processing}}

@STRING{iee_el = {{IEE} Electronics Lett.}}

@STRING{ieee_ac = {{IEEE} Aerospace Conf.}}

@STRING{ieee_dsp = {Proc. {IEEE} Intl. Conf. Digital Signal Processing ({DSP})}}

@STRING{ieee_icspcc = {Proc. {IEEE} Intl Conf. Signal Processing, Communications and Computing
	({ICSPCC})}}

@STRING{ieee_j_ac = {{IEEE} Trans. Autom. Control}}
@STRING{ieee_j_sel = {{IEEE} J. sel. Top. in Sig. Proc.}}

@STRING{ieee_j_advp = {{IEEE} Trans. Adv. Packag.}}

@STRING{ieee_j_aes = {{IEEE} Trans. Aerosp. Electron. Syst.}}

@STRING{ieee_j_aire = {{IEEE} Trans. Airborne Electron.}}

@STRING{ieee_j_ane = {{IEEE} Trans. Aerosp. Navig. Electron.}}

@STRING{ieee_j_anne = {{IEEE} Trans. Aeronaut. Navig. Electron.}}

@STRING{ieee_j_ap = {{IEEE} Trans. Antennas Propag.}}

@STRING{ieee_j_appind = {{IEEE} Trans. Appl. Ind.}}

@STRING{ieee_j_as = {{IEEE} Trans. Aerosp.}}

@STRING{ieee_j_asc = {{IEEE} Trans. Appl. Supercond.}}

@STRING{ieee_j_ase = {{IEEE} Trans. Autom. Sci. Eng.}}

@STRING{ieee_j_aslp = {{IEEE} Trans. Audio, Speech, Lang. Process.}}

@STRING{ieee_j_assp = {{IEEE} Trans. Acoust., Speech, Signal Process.}}


@STRING{ieee_j_au = {{IEEE} Trans. Audio}}

@STRING{ieee_j_auea = {{IEEE} Trans. Audio Electroacoust.}}

@STRING{ieee_j_awpl = {{IEEE} Antennas Wireless Propag. Lett.}}

@STRING{ieee_j_b-me = {{IEEE} Trans. Bio-Med. Eng.}}

@STRING{ieee_j_bc = {{IEEE} Trans. Broadcast.}}

@STRING{ieee_j_bme = {{IEEE} Trans. Biomed. Eng.}}

@STRING{ieee_j_bmelc = {{IEEE} Trans. Bio-Med. Electron.}}

@STRING{ieee_j_c = {{IEEE} Trans. Comput.}}

@STRING{ieee_j_cad = {{IEEE} Trans. Comput.-Aided Design Integr. Circuits Syst.}}

@STRING{ieee_j_cal = {{IEEE} Comput. Archit. Lett.}}

@STRING{ieee_j_capt = {{IEEE} Trans. Compon. Packag. Technol.}}

@STRING{ieee_j_capts = {{IEEE} Trans. Compon. Packag. Technol.}}

@STRING{ieee_j_cas = {{IEEE} Trans. Circuits Syst.}}

@STRING{ieee_j_casi = {{IEEE} Trans. Circuits Syst. {I}}}

@STRING{ieee_j_casi_rp = {{IEEE} Trans. Circuits Syst. {I}}}

@STRING{ieee_j_casii = {{IEEE} Trans. Circuits Syst. {II}}}

@STRING{ieee_j_casii_eb = {{IEEE} Trans. Circuits Syst. {II}}}

@STRING{ieee_j_casvt = {{IEEE} Trans. Circuits Syst. Video Technol.}}

@STRING{ieee_j_ce = {{IEEE} Trans. Consum. Electron.}}

@STRING{ieee_j_chmt = {{IEEE} Trans. Compon., Hybrids, Manuf. Technol.}}

@STRING{ieee_j_com = {{IEEE} Trans. Commun.}}

@STRING{ieee_j_coml = {{IEEE} Commun. Lett.}}

@STRING{ieee_j_comt = {{IEEE} Trans. Commun. Technol.}}

@STRING{ieee_j_cpart = {{IEEE} Trans. Compon. Parts}}

@STRING{ieee_j_cpmta = {{IEEE} Trans. Compon., Packag., Manuf. Technol. {A}}}

@STRING{ieee_j_cpmtb = {{IEEE} Trans. Compon., Packag., Manuf. Technol. {B}}}

@STRING{ieee_j_cpmtc = {{IEEE} Trans. Compon., Packag., Manuf. Technol. {C}}}

@STRING{ieee_j_cst = {{IEEE} Trans. Control Syst. Technol.}}

@STRING{ieee_j_ct = {{IEEE} Trans. Circuit Theory}}

@STRING{ieee_j_dei = {{IEEE} Trans. Dielectr. Electr. Insul.}}

@STRING{ieee_j_dmr = {{IEEE} Trans. Device Mater. Rel.}}

@STRING{ieee_j_ec = {{IEEE} Trans. Energy Convers.}}

@STRING{ieee_j_ecomp = {{IEEE} Trans. Electron. Comput.}}

@STRING{ieee_j_ed = {{IEEE} Trans. Electron Devices}}

@STRING{ieee_j_edl = {{IEEE} Electron Device Lett.}}

@STRING{ieee_j_edu = {{IEEE} Trans. Educ.}}

@STRING{ieee_j_ei = {{IEEE} Trans. Electr. Insul.}}

@STRING{ieee_j_em = {{IEEE} Trans. Eng. Manag.}}

@STRING{ieee_j_emc = {{IEEE} Trans. Electromagn. Compat.}}

@STRING{ieee_j_epm = {{IEEE} Trans. Electron. Packag. Manuf.}}

@STRING{ieee_j_essl = {{IEEE/ECS} Electrochem. Solid-State Lett.}}

@STRING{ieee_j_evc = {{IEEE} Trans. Evol. Comput.}}

@STRING{ieee_j_fuzz = {{IEEE} Trans. Fuzzy Syst.}}

@STRING{ieee_j_ge = {{IEEE} Trans. Geosci. Electron.}}

@STRING{ieee_j_grs = {{IEEE} Trans. Geosci. Remote Sens.}}

@STRING{ieee_j_grsl = {{IEEE} Geosci. Remote Sens. Lett.}}

@STRING{ieee_j_hfe = {{IEEE} Trans. Hum. Factors Electron.}}

@STRING{ieee_j_ia = {{IEEE} Trans. Ind. Appl.}}

@STRING{ieee_j_ie = {{IEEE} Trans. Ind. Electron.}}

@STRING{ieee_j_ieci = {{IEEE} Trans. Ind. Electron. Contr. Instrum.}}

@STRING{ieee_j_ifs = {{IEEE} Trans. Inf. Forensics Security}}

@STRING{ieee_j_iga = {{IEEE} Trans. Ind. Gen. Appl.}}

@STRING{ieee_j_iinf = {{IEEE} Trans. Ind. Informat.}}

@STRING{ieee_j_im = {{IEEE} Trans. Instrum. Meas.}}

@STRING{ieee_j_ip = {{IEEE} Trans. Image Process.}}

@STRING{ieee_j_it = {{IEEE} Trans. Inf. Theory}}

@STRING{ieee_j_itbm = {{IEEE} Trans. Inf. Technol. Biomed.}}

@STRING{ieee_j_its = {{IEEE} Trans. Intell. Transp. Syst.}}

@STRING{ieee_j_jdt = {{IEEE/OSA} J. Display Technol.}}

@STRING{ieee_j_jem = {{IEEE/TMS} J. Electron. Mater.}}

@STRING{ieee_j_jlt = {J. Lightw. Technol.}}

@STRING{ieee_j_jqe = {{IEEE} J. Quantum Electron.}}

@STRING{ieee_j_jra = {{IEEE} J. Robot. Autom.}}

@STRING{ieee_j_jsac = {{IEEE} J. Sel. Areas Commun.}}

@STRING{ieee_j_jssc = {{IEEE} J. Solid-State Circuits}}

@STRING{ieee_j_jstqe = {{IEEE} J. Sel. Topics Quantum Electron.}}

@STRING{ieee_j_kde = {{IEEE} Trans. Knowl. Data Eng.}}

@STRING{ieee_j_mag = {{IEEE} Trans. Magn.}}

@STRING{ieee_j_mc = {{IEEE} Trans. Mobile Comput.}}

@STRING{ieee_j_me = {{IEEE} Trans. Med. Electron.}}

@STRING{ieee_j_mech = {{IEEE/ASME} Trans. Mechatronics}}

@STRING{ieee_j_mems = {J. Microelectromech. Syst.}}

@STRING{ieee_j_mft = {{IEEE} Trans. Manuf. Technol.}}

@STRING{ieee_j_mgwl = {{IEEE} Microw. Guided Wave Lett.}}

@STRING{ieee_j_mi = {{IEEE} Trans. Med. Imag.}}

@STRING{ieee_j_mil = {{IEEE} Trans. Mil. Electron.}}

@STRING{ieee_j_mm = {{IEEE} Trans. Multimedia}}

@STRING{ieee_j_mms = {{IEEE} Trans. Man-Mach. Syst.}}

@STRING{ieee_j_mtt = {{IEEE} Trans. Microw. Theory Tech.}}

@STRING{ieee_j_mwcl = {{IEEE} Microw. Wireless Compon. Lett.}}

@STRING{ieee_j_nano = {{IEEE} Trans. Nanotechnol.}}

@STRING{ieee_j_nb = {{IEEE} Trans. Nanobiosci.}}

@STRING{ieee_j_net = {{IEEE/ACM} Trans. Netw.}}

@STRING{ieee_j_nn = {{IEEE} Trans. Neural Netw.}}

@STRING{ieee_j_ns = {{IEEE} Trans. Nucl. Sci.}}

@STRING{ieee_j_nsre = {{IEEE} Trans. Neural Syst. Rehabil. Eng.}}

@STRING{ieee_j_oe = {{IEEE} J. Ocean. Eng.}}

@STRING{ieee_j_pami = {{IEEE} Trans. Pattern Anal. Mach. Intell.}}

@STRING{ieee_j_pc = {{IEEE} Trans. Prof. Commun.}}

@STRING{ieee_j_pds = {{IEEE} Trans. Parallel Distrib. Syst.}}

@STRING{ieee_j_pel = {{IEEE} Power Electron. Lett.}}

@STRING{ieee_j_php = {{IEEE} Trans. Parts, Hybrids, Packag.}}

@STRING{ieee_j_pmp = {{IEEE} Trans. Parts, Mater., Packag.}}

@STRING{ieee_j_proc = {Proc. {IEEE}}}

@STRING{ieee_j_ps = {{IEEE} Trans. Plasma Sci.}}

@STRING{ieee_j_pse = {{IEEE} J. Product Safety Eng.}}

@STRING{ieee_j_ptl = {{IEEE} Photon. Technol. Lett.}}

@STRING{ieee_j_pwras = {{IEEE} Trans. Power App. Syst.}}

@STRING{ieee_j_pwrd = {{IEEE} Trans. Power Del.}}

@STRING{ieee_j_pwre = {{IEEE} Trans. Power Electron.}}

@STRING{ieee_j_pwrs = {{IEEE} Trans. Power Syst.}}

@STRING{ieee_j_r = {{IEEE} Trans. Rel.}}

@STRING{ieee_j_ra = {{IEEE} Trans. Robot. Autom.}}

@STRING{ieee_j_re = {{IEEE} Trans. Rehabil. Eng.}}

@STRING{ieee_j_rfi = {{IEEE} Trans. Radio Freq. Interference}}

@STRING{ieee_j_ro = {{IEEE} Trans. Robot.}}

@STRING{ieee_j_sap = {{IEEE} Trans. Speech Audio Process.}}

@STRING{ieee_j_se = {{IEEE} Trans. Softw. Eng.}}

@STRING{ieee_j_sensor = {{IEEE} Sensors J.}}

@STRING{ieee_j_sm = {{IEEE} Trans. Semicond. Manuf.}}

@STRING{ieee_j_smc = {{IEEE} Trans. Syst., Man, Cybern.}}

@STRING{ieee_j_smca = {{IEEE} Trans. Syst., Man, Cybern. {A}}}

@STRING{ieee_j_smcb = {{IEEE} Trans. Syst., Man, Cybern. {B}}}

@STRING{ieee_j_smcc = {{IEEE} Trans. Syst., Man, Cybern. {C}}}

@STRING{ieee_j_sp = {{IEEE} Trans. Signal Process.}}

@STRING{ieee_j_spl = {{IEEE} Signal Process. Lett.}}

@STRING{ieee_j_ssc = {{IEEE} Trans. Syst. Sci. Cybern.}}

@STRING{ieee_j_su = {{IEEE} Trans. Sonics Ultrason.}}

@STRING{ieee_j_tcad = {{IEEE} J. Technol. Comput. Aided Design}}

@STRING{ieee_j_tjmj = {{IEEE} Transl. J. Magn. Jpn.}}

@STRING{ieee_j_ue = {{IEEE} Trans. Ultrason. Eng.}}

@STRING{ieee_j_uffc = {{IEEE} Trans. Ultrason., Ferroelectr., Freq. Control}}

@STRING{ieee_j_vc = {{IEEE} Trans. Veh. Commun.}}

@STRING{ieee_j_vcg = {{IEEE} Trans. Vis. Comput. Graphics}}

@STRING{ieee_j_vlsi = {{IEEE} Trans. {VLSI} Syst.}}

@STRING{ieee_j_vt = {{IEEE} Trans. Veh. Technol.}}

@STRING{ieee_j_wcom = {{IEEE} Trans. Wireless Commun.}}

@STRING{ieee_m_aes = {{IEEE} Aerosp. Electron. Syst. Mag.}}

@STRING{ieee_m_ap = {{IEEE} Antennas Propag. Mag.}}

@STRING{ieee_m_assp = {{IEEE} {ASSP} Mag.}}

@STRING{ieee_m_c = {{IEEE} Computer}}

@STRING{ieee_m_cap = {{IEEE} Comput. Appl. Power}}

@STRING{ieee_m_cas = {{IEEE} Circuits Syst. Mag.}}

@STRING{ieee_m_cd = {{IEEE} Circuits Devices Mag.}}

@STRING{ieee_m_cga = {{IEEE} Comput. Graph. Appl.}}

@STRING{ieee_m_cim = {{IEEE} Comput. Intell. Mag.}}

@STRING{ieee_m_com = {{IEEE} Commun. Mag.}}

@STRING{ieee_m_comsoc = {{IEEE} Commun. Soc. Mag.}}

@STRING{ieee_m_conc = {{IEEE} Concurrency}}

@STRING{ieee_m_cs = {{IEEE} Control Syst. Mag.}}

@STRING{ieee_m_cse = {{IEEE} Comput. Sci. Eng.}}

@STRING{ieee_m_csem = {{IEEE} Comput. Sci. Eng. Mag.}}

@STRING{ieee_m_dtc = {{IEEE} Des. Test. Comput.}}

@STRING{ieee_m_ei = {{IEEE} Electr. Insul. Mag.}}

@STRING{ieee_m_emb = {{IEEE} Eng. Med. Biol. Mag.}}

@STRING{ieee_m_emr = {{IEEE} Eng. Manag. Rev.}}

@STRING{ieee_m_etr = {{IEEE} ElectroTechnol. Rev.}}

@STRING{ieee_m_exp = {{IEEE} Expert}}

@STRING{ieee_m_hist = {{IEEE} Ann. Hist. Comput.}}

@STRING{ieee_m_ia = {{IEEE} Ind. Appl. Mag.}}

@STRING{ieee_m_ic = {{IEEE} Internet Comput.}}

@STRING{ieee_m_im = {{IEEE} Instrum. Meas. Mag.}}

@STRING{ieee_m_is = {{IEEE} Intell. Syst.}}

@STRING{ieee_m_itp = {{IEEE} {IT} Prof.}}

@STRING{ieee_m_micro = {{IEEE} Micro}}

@STRING{ieee_m_mm = {{IEEE} Multimedia}}

@STRING{ieee_m_mw = {{IEEE} Microw. Mag.}}

@STRING{ieee_m_net = {{IEEE} Netw.}}

@STRING{ieee_m_pcom = {{IEEE} Personal Commun. Mag.}}

@STRING{ieee_m_pe = {{IEEE} Power Energy Mag.}}

@STRING{ieee_m_per = {{IEEE} Power Eng. Rev.}}

@STRING{ieee_m_pot = {{IEEE} Potentials}}

@STRING{ieee_m_pvc = {{IEEE} Pervasive Comput.}}

@STRING{ieee_m_ra = {{IEEE} Robot. Autom. Mag.}}

@STRING{ieee_m_s = {{IEEE} Softw.}}

@STRING{ieee_m_sap = {{IEEE} Security Privacy}}

@STRING{ieee_m_sp = {{IEEE} Signal Process. Mag.}}

@STRING{ieee_m_spect = {{IEEE} Spectr.}}

@STRING{ieee_m_today = {Today's Engineer}}

@STRING{ieee_m_ts = {{IEEE} Technol. Soc. Mag.}}

@STRING{ieee_m_vt = {{IEEE} Veh. Technol. Mag.}}

@STRING{ieee_m_wc = {{IEEE} Wireless Commun. Mag.}}

@STRING{ieee_o_csto = {{IEEE} Commun. Surveys Tuts.}}

@STRING{ieee_spwhos = {{IEEE} Signal Processing Workshop on Higher-Order Statistics ({SPW-HOS})}}

@STRING{ieee_ssap = {Proc. {IEEE} Signal Process. Workshop on Statistical Signal and Array
	Process. (SSAP)}}

@STRING{ieeeacm_j_aslp = {{IEEE/ACM} Trans. Audio, Speech, Lang. Process.}}

@STRING{ieeei = {Proc. {IEEE} Convention of Electrical \& Electronics Engineers in
	Israel (IEEEI)}}

@STRING{indicon = {Proc. {IEEE} {INDICON}}}

@STRING{interspeech = {Proc. Interspeech Conf.}}

@STRING{ire = {{IRE} Transactions on Information Theory}}

@STRING{iscas = {Proc. Intl. Symp. on Circuits and Systems}}

@STRING{isccsp = {Proc. Intl. Symp. on Control, Commmunications and Signal Processing}}

@STRING{isicabss = {Proc. Intl. Symp. on Independent Component Analysis and Blind Signal
	Separation}}

@STRING{ism = {Proc. {IEEE} Intl. Symposium on Multimedia ({ISM})}}

@STRING{isspa = {Proc. Intl. Symposium on Signal Processing and its Applications (ISSPA)}}

@STRING{isspit = {Proc. Intl. Symposium on Signal Processing and Information Technology
	(ISSPIT)}}

@STRING{its = {Proc. Intl. Telecommunications Symposium ({ITS})}}

@STRING{iwaenc = {Proc. Intl. Workshop Acoust. Signal Enhancement ({IWAENC})}}

@STRING{iwaenc_pre_2012 = {Proc. Intl. Workshop Acoust. Echo Noise Control ({IWAENC})}}

@STRING{iwase = {Proc. Intl. Workshop Acoust. Signal Enhancement ({IWAENC})}}

@STRING{iwssp = {Proc. {IEEE} Workshop Statistical Signal Processing}}

@STRING{j_aes = {Journal Audio Eng. Soc.}}

@STRING{j_aesj = {Journal Audio Eng. Soc. of Japan}}

@STRING{j_asa = {J. Acoust. Soc. Am.}}

@STRING{j_asj = {J. Acoust. Soc. Japan}}

@STRING{j_ast = {Acoustical Science and Technology}}

@STRING{j_automatica = {Automatica}}

@STRING{j_cam = {Journal of Computational and Applied Mathematics}}

@STRING{j_ccc = {Intl. Journal of Computers, Communications and Control}}

@STRING{j_csl = {Computer Speech and Language}}

@STRING{j_ent = {Ear, Nose and Throat Journal}}

@STRING{j_exp_psy = {J. Exp. Psychol.}}

@STRING{j_ieice = {{IEICE} Technical Report}}

@STRING{j_inf = {Informatica}}

@STRING{j_itc = {Intl. Journal of Applied Research on Information Technology and Computing}}

@STRING{j_lcd = {Intl. Journal of Language and Communication Disorders}}

@STRING{j_nmr = {Journal of New Music Research}}

@STRING{j_phonet = {Journal of Phonetics}}

@STRING{j_pp = {Perception \& Psychophysics}}

@STRING{j_shr = {Journal of Speech and Hearing Research}}

@STRING{j_slhr = {Journal of Speech, Language and Hearing Research}}

@STRING{j_sp = {Signal Processing}}

@STRING{j_spcom = {Speech Communication}}

@STRING{j_sv = {Journal of Sound and Vibration}}

@STRING{j_v = {Journal of Voice}}

@STRING{j_vr = {Vision Research}}

@STRING{mep = {Journal of Medical Engineering \& Physics}}

@STRING{ncc = {Proc. National Conference on Communications ({NCC}), India}}

@STRING{neurocomp = {Neurocomputing}}

@STRING{nips = {Proc. Neural Information Processing Conf}}

@STRING{nolisp = {Proc. Nonlinear Speech Processing}}

@STRING{pacrim = {IEEE Pacific Rim Conf. on Communications, Computers and Signal Processing}}

@STRING{prorisc = {Proc. Workshop Circuits, Systems and Signal Processing ({ProRISC})}}

@STRING{ptrsl = {Philos. Trans. Royal Soc. London}}

@STRING{pub-ap = {Academic Press}}

@STRING{pub-ap:adr = {New York, {NY}, {USA}}}

@STRING{pub-aw = {Addison-Wesley}}

@STRING{pub-birkhauser = {Birkh{\"{a}}user}}

@STRING{pub-birkhauser:adr = {Cambridge, MA, USA; Berlin, Germany;Basel,Switzerland}}

@STRING{pub-cp = {Clarendon Press}}

@STRING{pub-crc = {CRC Press}}

@STRING{pub-crc:adr = {2000 Corporate Blvd., Boca Raton, FL 33431, {USA}}}

@STRING{pub-cup = {Cambridge University Press}}

@STRING{pub-cup:adr = {Cambridge, {UK}}}

@STRING{pub-dover = {Dover Publications}}

@STRING{pub-dover:adr = {New York, {USA}}}

@STRING{pub-esp = {Elsevier Science Publishers B. V.}}

@STRING{pub-esp:adr = {Amsterdam, The Netherlands}}

@STRING{pub-hrw = {Holt, Rinehart, and Winston}}

@STRING{pub-hrw:adr = {New York, {NY}, {USA}}}

@STRING{pub-ieee = {IEEE Computer Society Press}}

@STRING{pub-ieee:adr = {1109 Spring Street, Suite 300, Silver Spring, {MD} 20910, {USA}}}

@STRING{pub-jws = {John Wiley \& Sons}}

@STRING{pub-jws:adr = {New York, NY, USA}}

@STRING{pub-kap = {Kluwer Academic Publisher}}

@STRING{pub-kap:adr = {Norwell, MA, USA, and Dordrecht, The Netherlands}}

@STRING{pub-mh = {McGraw-Hill}}

@STRING{pub-mh:adr = {New York, NY, USA}}

@STRING{pub-ph = {Prentice-Hall}}

@STRING{pub-ph:adr = {Englewood Cliffs, NJ 07632, USA}}

@STRING{pub-siam = {SIAM}}

@STRING{pub-siam:adr = {Philadelphia, PA, USA}}

@STRING{pub-sv = {Spring{\-}er-Ver{\-}lag}}

@STRING{pub-sv:adr = {Berlin, Germany~/ Heidelberg, Germany~/ London, UK~/ etc.}}

@STRING{pub-teu = {Teubner Verlag}}

@STRING{pub-teu:adr = {Stuttgart, Germany}}

@STRING{rlsp = {Research Letters in Signal Processing}}

@STRING{scored = {Proc. Student Conf. Research and Development ({SCORED})}}

@STRING{scw = {Proc. {IEEE} Speech Coding Workshop}}

@STRING{siam = {SIAM Journal Sci. Comput.}}

@STRING{siamrev = {{SIAM} Review}}

@STRING{siu = {Proc. Signal Processing and Communications Applications Conference
	(SIU), Turkey}}

@STRING{spat = {Proc. Intl. Conf. on Sig. Proc. Applications and Technology}}

@STRING{specom = {Proc. Speech and Computers}}

@STRING{spen = {Speech Enhancement}}

@STRING{spieaaasp = {Proc. SPIE Adv. Algorithms Architectures Signal Processing}}

@STRING{sps-2000 = {Proc. 2nd {IEEE} Benelux Signal Processing Symposium ({SPS}-2000)}}

@STRING{ssp = {Proc. {IEEE/SP} Workshop on Statistical Signal Processing}}

@STRING{stl-qpsr = {STL-QPSR}}

@STRING{stl_qpsr = {STL-QPSR}}

@STRING{tmh-qpsr = {TMH-QPSR}}

@STRING{vtconf = {Proc. {IEEE} Vechicular Technology Conf.}}

@STRING{waspaa = {Proc. {IEEE} Workshop on Applications of Signal Processing to Audio
	and Acoustics ({WASPAA})}}

@STRING{wcecs = {Proc. World Congress on Engineering and Computer Science ({WCECS})}}

@STRING{wicass = {Proc. Intl. Workshop on Independent Component Analysis and Signal
	Separation}}
@STRING{ismir = {Intl. Soc. of Music Inf. Retrieval}}
@STRING{wsc = {Proc. {IEEE} Workshop on Speech Coding}}
@STRING{ICLR = {Proc. {IEEE} Intl. Conf. on Learn. Repr. (ICLR)}}

@STRING{wasru = {Proc. {IEEE} Workshop on Automatic Speech Recognition and Understanding}}


@book{mahanta_directionality_2008,
	title = {Directionality and locality in vowel harmony: {With} special reference to vowel harmony in {Assamese}},
	publisher = {Netherlands Graduate School of Linguistics},
	author = {Mahanta, Shakuntala},
	year = {2008},
}

@phdthesis{mahanta_directionality_2007,
	type = {{PhD} {Thesis}},
	title = {Directionality and locality in vowel harmony},
	school = {Utrecht University},
	author = {Mahanta, Shakuntala},
	year = {2007},
}

@article{mahanta_assamese_2012,
	title = {Assamese},
	volume = {42},
	number = {2},
	journal = {Journal of the International Phonetic Association},
	author = {Mahanta, Shakuntala},
	year = {2012},
	note = {Publisher: Cambridge University Press},
	pages = {217--224},
}

@article{archangeli_assamese_2020,
	title = {Assamese vowels and vowel harmony},
	volume = {6},
	number = {2},
	journal = {Journal of South Asian Languages and Linguistics},
	author = {Archangeli, Diana B and Yip, Jonathan},
	year = {2020},
	note = {Publisher: De Gruyter},
	pages = {151--183},
}

@book{kager_optimality_1999,
	title = {Optimality theory},
	publisher = {Cambridge university press},
	author = {Kager, René},
	year = {1999},
}

@article{saffran_statistical_1996,
	title = {Statistical learning by 8-month-old infants},
	volume = {274},
	number = {5294},
	journal = {Science},
	author = {Saffran, Jenny R and Aslin, Richard N and Newport, Elissa L},
	year = {1996},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {1926--1928},
}

@article{saffran_infants_2007,
	title = {The infant's auditory world: {Hearing}, speech, and the beginnings of language},
	volume = {2},
	journal = {Handbook of child psychology},
	author = {Saffran, Jenny R and Werker, Janet F and Werner, Lynne A},
	year = {2007},
	note = {Publisher: Wiley Online Library},
}

@article{kuhl_brain_2010,
	title = {Brain mechanisms in early language acquisition},
	volume = {67},
	number = {5},
	journal = {Neuron},
	author = {Kuhl, Patricia K},
	year = {2010},
	note = {Publisher: Elsevier},
	pages = {713--727},
}

@article{clements_role_1990,
	title = {The role of the sonority cycle in core syllabification},
	journal = {Papers in laboratory phonology},
	author = {Clements, George N},
	year = {1990},
	note = {Publisher: Cambridge University Press},
	pages = {283--333},
}

@article{henderson_khasi_1976,
	title = {Khasi initial clusters},
	number = {13},
	journal = {Oceanic Linguistics Special Publications},
	author = {Henderson, Eugénie JA},
	year = {1976},
	note = {Publisher: JSTOR},
	pages = {523--538},
}

@article{rabel_khasi_1961,
	title = {Khasi, a language of {Assam}},
	journal = {(No Title)},
	author = {Rabel, Lili},
	year = {1961},
}

@article{ring_grammar_2015,
	title = {A grammar of {Pnar}},
	journal = {Unpublished PhD dissertation, Nanyang Technological University, Singapore},
	author = {Ring, Hiram},
	year = {2015},
}

@book{whorf_linguistics_1940,
	title = {Linguistics as an exact science},
	publisher = {Massachusetts Institute of Technology},
	author = {Whorf, Benjamin Lee},
	year = {1940},
}

@book{kager_optimality_1999-1,
	title = {Optimality theory},
	publisher = {Cambridge university press},
	author = {Kager, René},
	year = {1999},
}

@article{kang_english_1996,
	title = {English loanword in {Korean}},
	volume = {2},
	journal = {음성음운형태론연구},
	author = {Kang, Hyunsook},
	year = {1996},
	pages = {21--47},
}

@article{ring_phonetic_2012,
	title = {A phonetic description and phonemic analysis of {Jowai}-{Pnar}},
	volume = {40},
	journal = {Mon-Khmer Studies},
	author = {Ring, Hiram},
	year = {2012},
	pages = {133--175},
}

@book{tessier_phonological_2017,
	title = {Phonological acquisition: {Child} language and constraint-based grammar},
	publisher = {Bloomsbury Publishing},
	author = {Tessier, Anne-Michelle},
	year = {2017},
}

@article{albright_learning_2011,
	title = {Learning and learnability in phonology},
	journal = {The handbook of phonological theory},
	author = {Albright, Adam and Hayes, Bruce},
	year = {2011},
	note = {Publisher: Wiley Online Library},
	pages = {661--690},
}

@article{jarosz_computational_2019,
	title = {Computational modeling of phonological learning},
	volume = {5},
	journal = {Annual Review of Linguistics},
	author = {Jarosz, Gaja},
	year = {2019},
	note = {Publisher: Annual Reviews},
	pages = {67--90},
}

@article{hayes_maximum_2008,
	title = {A maximum entropy model of phonotactics and phonotactic learning},
	volume = {39},
	number = {3},
	journal = {Linguistic inquiry},
	author = {Hayes, Bruce and Wilson, Colin},
	year = {2008},
	note = {Publisher: MIT press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info …},
	pages = {379--440},
}

@article{albright_feature-based_2009,
	title = {Feature-based generalisation as a source of gradient acceptability},
	volume = {26},
	number = {1},
	journal = {Phonology},
	author = {Albright, Adam},
	year = {2009},
	note = {Publisher: Cambridge University Press},
	pages = {9--41},
}

@article{futrell_generative_2017,
	title = {A generative model of phonotactics},
	volume = {5},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Futrell, Richard and Albright, Adam and Graff, Peter and O’Donnell, Timothy J},
	year = {2017},
	note = {Publisher: MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info …},
	pages = {73--86},
}

@article{daland_explaining_2011,
	title = {Explaining sonority projection effects},
	volume = {28},
	number = {2},
	journal = {Phonology},
	author = {Daland, Robert and Hayes, Bruce and White, James and Garellek, Marc and Davis, Andrea and Norrmann, Ingrid},
	year = {2011},
	note = {Publisher: Cambridge University Press},
	pages = {197--234},
}

@inproceedings{jarosz_sonority_2017,
	title = {Sonority sequencing in {Polish}: {The} combined roles of prior bias \& experience},
	volume = {4},
	booktitle = {Proceedings of the annual meetings on phonology},
	author = {Jarosz, Gaja and Rysling, Amanda},
	year = {2017},
}

@article{prince_optimality_2004,
	title = {Optimality {Theory}: {Constraint} interaction in generative grammar},
	journal = {Optimality Theory in phonology: A reader},
	author = {Prince, Alan and Smolensky, Paul},
	year = {2004},
	note = {Publisher: Wiley Online Library},
	pages = {1--71},
}

@article{tesar_learnability_1995,
	title = {The learnability of {Optimality} {Theory}: {An} algorithm and some basic complexity results},
	author = {Tesar, Bruce and Smolensky, Paul},
	year = {1995},
	note = {Publisher: Johns Hopkins University, Department of Computer Science},
}

@book{legendre_can_1990,
	title = {Can connectionism contribute to syntax?: {Harmonic} {Grammar}, with an application},
	publisher = {University of Colorado, Boulder, Department of Computer Science},
	author = {Legendre, Géraldine and Miyata, Yoshiro and Smolensky, Paul},
	year = {1990},
}

@book{smolensky_harmonic_2006,
	title = {The harmonic mind: {From} neural computation to optimality-theoretic grammar ({Cognitive} architecture), {Vol}. 1},
	publisher = {MIT press},
	author = {Smolensky, Paul and Legendre, Géraldine},
	year = {2006},
}

@article{pater_weighted_2009,
	title = {Weighted constraints in generative linguistics},
	volume = {33},
	number = {6},
	journal = {Cognitive science},
	author = {Pater, Joe},
	year = {2009},
	note = {Publisher: Wiley Online Library},
	pages = {999--1035},
}

@article{smolensky_optimality_2006,
	title = {Optimality in phonology {II}: {Harmonic} completeness, local constraint conjunction, and feature domain markedness},
	volume = {2},
	journal = {The harmonic mind: From neural computation to optimality-theoretic grammar},
	author = {Smolensky, Paul and {others}},
	year = {2006},
	note = {Publisher: Citeseer},
	pages = {27--160},
}

@article{boersma_convergence_2016,
	title = {Convergence properties of a gradual learning algorithm for {Harmonic} {Grammar}},
	author = {Boersma, Paul and Pater, Joe and {others}},
	year = {2016},
	note = {Publisher: Sheffield, UKEquinox},
}

@inproceedings{hayes_varieties_2017,
	title = {Varieties of noisy harmonic grammar},
	volume = {4},
	booktitle = {Proceedings of the annual meetings on phonology},
	author = {Hayes, Bruce},
	year = {2017},
}

@article{boersma_empirical_2001,
	title = {Empirical tests of the gradual learning algorithm},
	volume = {32},
	number = {1},
	journal = {Linguistic inquiry},
	author = {Boersma, Paul and Hayes, Bruce},
	year = {2001},
	note = {Publisher: MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info …},
	pages = {45--86},
}

@book{boersma_functional_1998,
	title = {Functional phonology},
	publisher = {Netherlands Graduate School of Linguistics},
	author = {Boersma, Paul},
	year = {1998},
}

@inproceedings{goldwater_learning_2003,
	title = {Learning {OT} constraint rankings using a maximum entropy model},
	volume = {111},
	booktitle = {Proceedings of the {Stockholm} workshop on variation within {Optimality} {Theory}},
	author = {Goldwater, Sharon and Johnson, Mark and Spenader, Jennifer and Eriksson, Anders and Dahl, Osten},
	year = {2003},
	pages = {120},
}

@article{daland_what_2014,
	title = {What is computational phonology?},
	volume = {1},
	number = {1},
	journal = {Loquens},
	author = {Daland, Robert},
	year = {2014},
	pages = {e004--e004},
}

@article{pater_generative_2019,
	title = {Generative linguistics and neural networks at 60: {Foundation}, friction, and fusion},
	volume = {95},
	number = {1},
	journal = {Language},
	author = {Pater, Joe},
	year = {2019},
	note = {Publisher: Linguistic Society of America},
	pages = {e41--e74},
}

@article{hayes_maximum_2008-1,
	title = {A maximum entropy model of phonotactics and phonotactic learning},
	volume = {39},
	number = {3},
	journal = {Linguistic inquiry},
	author = {Hayes, Bruce and Wilson, Colin},
	year = {2008},
	note = {Publisher: MIT press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info …},
	pages = {379--440},
}

@article{mayer_phonotactic_2020,
	title = {Phonotactic learning with neural language models},
	volume = {3},
	number = {1},
	journal = {Proceedings of the Society for Computation in Linguistics},
	author = {Mayer, Connor and Nelson, Max},
	year = {2020},
	pages = {149--159},
}

@article{albright_rules_2003,
	title = {Rules vs. analogy in {English} past tenses: {A} computational/experimental study},
	volume = {90},
	number = {2},
	journal = {Cognition},
	author = {Albright, Adam and Hayes, Bruce},
	year = {2003},
	note = {Publisher: Elsevier},
	pages = {119--161},
}

@inproceedings{kirov_recurrent_2017,
	title = {Recurrent neural networks as a strong domain-general baseline for morpho-phonological learning},
	booktitle = {Poster presented at the 2017 {Meeting} of the {Linguistic} {Society} of {America}},
	author = {Kirov, Christo},
	year = {2017},
}

@article{kirov_recurrent_2018,
	title = {Recurrent neural networks in linguistic theory: {Revisiting} {Pinker} and {Prince} (1988) and the past tense debate},
	volume = {6},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Kirov, Christo and Cotterell, Ryan},
	year = {2018},
	note = {Publisher: MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info …},
	pages = {651--665},
}

@article{elman_finding_1990,
	title = {Finding structure in time},
	volume = {14},
	number = {2},
	journal = {Cognitive science},
	author = {Elman, Jeffrey L},
	year = {1990},
	note = {Publisher: Wiley Online Library},
	pages = {179--211},
}

@article{boersma_neural_2020,
	title = {Neural network models for phonology and phonetics},
	volume = {8},
	number = {1},
	journal = {Journal of Language Modelling},
	author = {Boersma, Paul and Benders, Titia and Seinhorst, Klaas},
	year = {2020},
	pages = {103--177},
}

@article{prickett_learning_2022,
	title = {Learning reduplication with a neural network that lacks explicit variables},
	volume = {10},
	number = {1},
	journal = {Journal of Language Modelling},
	author = {Prickett, Brandon and Traylor, Aaron and Pater, Joe},
	year = {2022},
	pages = {1--38},
}

@article{dupoux_cognitive_2018,
	title = {Cognitive science in the era of artificial intelligence: {A} roadmap for reverse-engineering the infant language-learner},
	volume = {173},
	journal = {Cognition},
	author = {Dupoux, Emmanuel},
	year = {2018},
	note = {Publisher: Elsevier},
	pages = {43--59},
}

@book{johnson_talker_1997,
	title = {Talker variability in speech processing},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Johnson, Keith and Mullennix, John W},
	year = {1997},
}

@article{johnson_decisions_2007,
	title = {Decisions and mechanisms in exemplar-based phonology},
	journal = {Experimental approaches to phonology},
	author = {Johnson, Keith},
	year = {2007},
	note = {Publisher: Oxford University Press Oxford},
	pages = {25--40},
}

@article{pierrehumbert_exemplar_2001,
	title = {Exemplar dynamics: {Word} frequency, lenition and contrast},
	volume = {45},
	journal = {Typological studies in language},
	author = {Pierrehumbert, Janet B},
	year = {2001},
	pages = {137--158},
}

@article{gahl_introduction_2006,
	title = {Introduction to the special issue on exemplar-based models in linguistics},
	author = {Gahl, Susanne and Yu, Alan C L},
	year = {2006},
	note = {Publisher: Walter de Gruyter},
}

@article{kaplan_exemplar-based_2017,
	title = {Exemplar-based models in linguistics},
	journal = {Oxford Bibliographies in Linguistics},
	author = {Kaplan, A},
	year = {2017},
}

@inproceedings{kello_interplay_2003,
	title = {The interplay of perception and production in phonological development: {Beginnings} of a connectionist model trained on real speech},
	booktitle = {5th {International} {Congress} of {Phonetic} {Sciences}, eds {MJ} {Solé}, {D}. {Recasens}, and {J}. {Romero} ({Barcelona})},
	author = {Kello, Christopher T and Plaut, David C},
	year = {2003},
	pages = {297--300},
}

@article{martin_learning_2013,
	title = {Learning phonemes with a proto-lexicon},
	volume = {37},
	number = {1},
	journal = {Cognitive science},
	author = {Martin, Andrew and Peperkamp, Sharon and Dupoux, Emmanuel},
	year = {2013},
	note = {Publisher: Wiley Online Library},
	pages = {103--124},
}

@article{faruqui_morphological_2015,
	title = {Morphological inflection generation using character sequence to sequence learning},
	journal = {arXiv preprint arXiv:1512.06110},
	author = {Faruqui, Manaal and Tsvetkov, Yulia and Neubig, Graham and Dyer, Chris},
	year = {2015},
}

@inproceedings{silfverberg_sound_2018,
	title = {Sound analogies with phoneme embeddings},
	booktitle = {Proceedings of the {Society} for {Computation} in {Linguistics} ({SCiL}) 2018},
	author = {Silfverberg, Miikka and Mao, Lingshuang Jack and Hulden, Mans},
	year = {2018},
	pages = {136--144},
}

@article{guenther_neural_2012,
	title = {A neural theory of speech acquisition and production},
	volume = {25},
	number = {5},
	journal = {Journal of neurolinguistics},
	author = {Guenther, Frank H and Vladusich, Tony},
	year = {2012},
	note = {Publisher: Elsevier},
	pages = {408--422},
}

@article{kirby_bias_2015,
	title = {Bias and population structure in the actuation of sound change},
	journal = {arXiv preprint arXiv:1507.04420},
	author = {Kirby, James and Sonderegger, Morgan},
	year = {2015},
}

@article{mcclelland_trace_1986,
	title = {The {TRACE} model of speech perception},
	volume = {18},
	number = {1},
	journal = {Cognitive psychology},
	author = {McClelland, James L and Elman, Jeffrey L},
	year = {1986},
	note = {Publisher: Elsevier},
	pages = {1--86},
}

@article{gaskell_connectionist_1995,
	title = {A connectionist model of phonological representation in speech perception},
	volume = {19},
	number = {4},
	journal = {Cognitive science},
	author = {Gaskell, M Gareth and Hare, Mary and Marslen-Wilson, William D},
	year = {1995},
	note = {Publisher: Elsevier},
	pages = {407--439},
}

@incollection{plant_emergence_2013,
	title = {The emergence of phonology from the interplay of speech comprehension and production: {A} distributed connectionist approach},
	booktitle = {The emergence of language},
	publisher = {Psychology Press},
	author = {Plant, David C and Kello, Christopher T},
	year = {2013},
	pages = {399--434},
}

@inproceedings{rasanen_analyzing_2016,
	title = {Analyzing distributional learning of phonemic categories in unsupervised deep neural networks},
	volume = {2016},
	booktitle = {{CogSci}... {Annual} {Conference} of the {Cognitive} {Science} {Society}. {Cognitive} {Science} {Society} ({US}). {Conference}},
	publisher = {NIH Public Access},
	author = {Räsänen, Okko and Nagamine, Tasha and Mesgarani, Nima},
	year = {2016},
	pages = {1757},
}

@inproceedings{shain_measuring_2019,
	title = {Measuring the perceptual availability of phonological features during language acquisition using unsupervised binary stochastic autoencoders},
	booktitle = {Proceedings of the 2019 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} and {Short} {Papers})},
	author = {Shain, Cory and Elsner, Micha},
	year = {2019},
	pages = {69--85},
}

@article{goodfellow_generative_2014,
	title = {Generative adversarial nets},
	volume = {27},
	journal = {Advances in neural information processing systems},
	author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	year = {2014},
}

@article{donahue_adversarial_2018,
	title = {Adversarial audio synthesis},
	journal = {arXiv preprint arXiv:1802.04208},
	author = {Donahue, Chris and McAuley, Julian and Puckette, Miller},
	year = {2018},
}

@article{radford_unsupervised_2015,
	title = {Unsupervised representation learning with deep convolutional generative adversarial networks},
	journal = {arXiv preprint arXiv:1511.06434},
	author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
	year = {2015},
}

@article{chen_infogan_2016,
	title = {Infogan: {Interpretable} representation learning by information maximizing generative adversarial nets},
	volume = {29},
	journal = {Advances in neural information processing systems},
	author = {Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
	year = {2016},
}

@article{begus_ciwgan_2021,
	title = {{CiwGAN} and {fiwGAN}: {Encoding} information in acoustic data to model lexical learning with {Generative} {Adversarial} {Networks}},
	volume = {139},
	journal = {Neural Networks},
	author = {Beguš, Gašper},
	year = {2021},
	note = {Publisher: Elsevier},
	pages = {305--325},
}

@article{begus_generative_2020,
	title = {Generative adversarial phonology: {Modeling} unsupervised phonetic and phonological learning with neural networks},
	volume = {3},
	journal = {Frontiers in artificial intelligence},
	author = {Beguš, Gašper},
	year = {2020},
	note = {Publisher: Frontiers Media SA},
	pages = {44},
}

@article{begus_interpreting_2022,
	title = {Interpreting intermediate convolutional layers of generative {CNNs} trained on waveforms},
	volume = {30},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {Beguš, Gašper and Zhou, Alan},
	year = {2022},
	note = {Publisher: IEEE},
	pages = {3214--3229},
}

@article{begus_identity-based_2021,
	title = {Identity-based patterns in deep convolutional networks: {Generative} adversarial phonology and reduplication},
	volume = {9},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Beguš, Gašper},
	year = {2021},
	note = {Publisher: MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info …},
	pages = {1180--1196},
}

@article{garofolo_darpa_1993,
	title = {{DARPA} {TIMIT} acoustic-phonetic continous speech corpus {CD}-{ROM}. {NIST} speech disc 1-1.1},
	volume = {93},
	journal = {NASA STI/Recon technical report n},
	author = {Garofolo, John S and Lamel, Lori F and Fisher, William M and Fiscus, Jonathan G and Pallett, David S},
	year = {1993},
	pages = {27403},
}

@article{chen_exploring_2023,
	title = {Exploring {How} {Generative} {Adversarial} {Networks} {Learn} {Phonological} {Representations}},
	journal = {arXiv preprint arXiv:2305.12501},
	author = {Chen, Jingyi and Elsner, Micha},
	year = {2023},
}

@inproceedings{oudeyer_coupled_2001,
	address = {Berlin, Heidelberg},
	title = {Coupled {Neural} {Maps} for the {Origins} of {Vowel} {Systems}},
	isbn = {978-3-540-44668-2},
	abstract = {A unified connectionist model of the perceptual magnet effect (the perceptual warping of vowels) is proposed, and relies on the concept of population coding in neural maps. Unlike what has been often stated, we claim that the imprecision of the classical “sum of vectors” coding/decoding scheme is not a drawback and can account for psychological observations. Furthermore, we show that coupling these neural maps allows the formation of vowel systems, which are shared symbolic systems, from initially continuous and uniform perception and production. This has important consequences for existing theories of phonetics.},
	booktitle = {Artificial {Neural} {Networks} — {ICANN} 2001},
	publisher = {Springer Berlin Heidelberg},
	author = {Oudeyer, Pierre-yves},
	editor = {Dorffner, Georg and Bischof, Horst and Hornik, Kurt},
	year = {2001},
	pages = {1171--1176},
}

@inproceedings{oudeyer_phonemic_2002,
	title = {Phonemic coding might result from sensory-motor coupling dynamics},
	booktitle = {From animals to animats 7: {Proceedings} of the {Seventh} {International} {Conference} on {Simulation} of {Adaptive} {Behavior}, eds {B}. {Hallam}, {D}. {Floreano}, {J}. {Hallam}, {G}. {Hayes}, and {J}.-{A}. {M}. {Hallam}},
	publisher = {Cambridge, MA: MIT Press},
	author = {Oudeyer, Pierre-yves},
	year = {2002},
	pages = {406--416},
}

@article{oudeyer_self-organization_2005,
	title = {The self-organization of speech sounds},
	volume = {233},
	issn = {0022-5193},
	url = {https://www.sciencedirect.com/science/article/pii/S0022519304005053},
	doi = {https://doi.org/10.1016/j.jtbi.2004.10.025},
	abstract = {The speech code is a vehicle of language: it defines a set of forms used by a community to carry information. Such a code is necessary to support the linguistic interactions that allow humans to communicate. How then may a speech code be formed prior to the existence of linguistic interactions? Moreover, the human speech code is discrete and compositional, shared by all the individuals of a community but different across communities, and phoneme inventories are characterized by statistical regularities. How can a speech code with these properties form? We try to approach these questions in the paper, using the “methodology of the artificial”. We build a society of artificial agents, and detail a mechanism that shows the formation of a discrete speech code without pre-supposing the existence of linguistic capacities or of coordinated interactions. The mechanism is based on a low-level model of sensory–motor interactions. We show that the integration of certain very simple and non-language-specific neural devices leads to the formation of a speech code that has properties similar to the human speech code. This result relies on the self-organizing properties of a generic coupling between perception and production within agents, and on the interactions between agents. The artificial system helps us to develop better intuitions on how speech might have appeared, by showing how self-organization might have helped natural selection to find speech.},
	number = {3},
	journal = {Journal of Theoretical Biology},
	author = {Oudeyer, Pierre-yves and Oudeyer, Pierre-Yves},
	year = {2005},
	keywords = {Phonetics, Phonology, Agents, Artificial systems, Evolution, Forms, Origins of speech sounds, Self-organization},
	pages = {435--449},
}

@incollection{oudeyer_index_2006,
	title = {Index},
	isbn = {978-0-19-928915-8},
	booktitle = {Self-{Organization} in the {Evolution} of {Speech}},
	publisher = {Oxford University Press},
	author = {Oudeyer, Pierre-yves},
	month = apr,
	year = {2006},
	doi = {10.1093/acprof:oso/9780199289158.001.0001},
	doi = {10.1093/acprof:oso/9780199289158.001.0001},
}

@book{guenther_neural_2016,
	title = {Neural {Control} of {Speech}},
	isbn = {978-0-262-33698-7},
	url = {https://doi.org/10.7551/mitpress/10471.001.0001},
	abstract = {A comprehensive and unified account of the neural computations underlying speech production, offering a theoretical framework bridging the behavioral and the neurological literatures.In this book, Frank Guenther offers a comprehensive, unified account of the neural computations underlying speech production, with an emphasis on speech motor control rather than linguistic content. Guenther focuses on the brain mechanisms responsible for commanding the musculature of the vocal tract to produce articulations that result in an acoustic signal conveying a desired string of syllables. Guenther provides neuroanatomical and neurophysiological descriptions of the primary brain structures involved in speech production, looking particularly at the cerebral cortex and its interactions with the cerebellum and basal ganglia, using basic concepts of control theory (accompanied by nontechnical explanations) to explore the computations performed by these brain regions.Guenther offers a detailed theoretical framework to account for a broad range of both behavioral and neurological data on the production of speech. He discusses such topics as the goals of the neural controller of speech; neural mechanisms involved in producing both short and long utterances; and disorders of the speech system, including apraxia of speech and stuttering. Offering a bridge between the neurological and behavioral literatures on speech production, the book will be a valuable resource for researchers in both fields.},
	publisher = {The MIT Press},
	author = {Guenther, Frank H.},
	month = jul,
	year = {2016},
	doi = {10.7551/mitpress/10471.001.0001},
}

@article{creswell_generative_2018,
	title = {Generative {Adversarial} {Networks}: {An} {Overview}},
	volume = {35},
	issn = {1053-5888},
	doi = {10.1109/msp.2017.2765202},
	number = {1},
	journal = {IEEE Signal Processing Magazine},
	author = {Creswell, Antonia and White, Tom and Dumoulin, Vincent and Arulkumaran, Kai and Sengupta, Biswa and Bharath, Anil A.},
	month = jan,
	year = {2018},
	note = {Publisher: Institute of Electrical and Electronics Engineers (IEEE)},
	pages = {53--65},
}

@article{yamagishi_siwis_2017,
	title = {The siwis {French} speech synthesis database},
	journal = {Idiap Research Institute, Tech. Rep},
	author = {Yamagishi, Junichi and Honnet, Pierre-Edouard and Garner, P and Lazaridis, Alexandros and {others}},
	year = {2017},
}

@book{chomsky_sound_1968,
	address = {New York, Evanston and London},
	title = {Sound {Patterns} of {English}},
	publisher = {Harper and Row},
	author = {Chomsky, Noam and Halle, Morris},
	year = {1968},
}

@article{heinz_learning_2010,
	title = {Learning {Long}-{Distance} {Phonotactics}},
	volume = {41},
	issn = {00243892, 15309150},
	url = {http://www.jstor.org/stable/40926398},
	number = {4},
	urldate = {2023-12-26},
	journal = {Linguistic Inquiry},
	author = {Heinz, Jeffrey},
	year = {2010},
	note = {Publisher: The MIT Press},
	pages = {623--661},
}

@article{gelderloos_phonemes_2016,
	title = {From phonemes to images: levels of representation in a recurrent neural model of visually-grounded language learning},
	volume = {abs/1610.03342},
	url = {http://arxiv.org/abs/1610.03342},
	journal = {CoRR},
	author = {Gelderloos, Lieke and Chrupala, Grzegorz},
	year = {2016},
	note = {arXiv: 1610.03342},
}

@inproceedings{chrupala_representations_2017,
	address = {Vancouver, Canada},
	title = {Representations of language in a model of visually grounded speech signal},
	url = {https://aclanthology.org/P17-1057},
	doi = {10.18653/v1/P17-1057},
	abstract = {We present a visually grounded model of speech perception which projects spoken utterances and images to a joint semantic space. We use a multi-layer recurrent highway network to model the temporal nature of spoken speech, and show that it learns to extract both form and meaning-based linguistic knowledge from the input signal. We carry out an in-depth analysis of the representations used by different components of the trained model and show that encoding of semantic aspects tends to become richer as we go up the hierarchy of layers, whereas encoding of form-related aspects of the language input tends to initially increase and then plateau or decrease.},
	booktitle = {Proceedings of the 55th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Chrupa{\textbackslash}la, Grzegorz and Gelderloos, Lieke and Alishahi, Afra},
	editor = {Barzilay, Regina and Kan, Min-Yen},
	month = jul,
	year = {2017},
	pages = {613--622},
}

@book{r_core_team_r_2021,
	address = {Vienna, Austria},
	title = {R: {A} {Language} and {Environment} for {Statistical} {Computing}},
	url = {https://www.R-project.org/},
	publisher = {R Foundation for Statistical Computing},
	author = {{R Core Team}},
	year = {2021},
}

@article{olejarczuk_acoustic_2019,
	title = {Acoustic correlates of anticipatory and progressive [{ATR}] harmony processes in {Ethiopian} {Komo}},
	volume = {74},
	issn = {0095-4470},
	url = {https://www.sciencedirect.com/science/article/pii/S0095447018300147},
	doi = {https://doi.org/10.1016/j.wocn.2019.01.004},
	abstract = {Komo, an endangered Koman language spoken in Western Ethiopia, features a system of vowel assimilation commonly referred to as ‘advanced tongue root’ (ATR) harmony. Prior accounts of Komo [ATR] harmony describe a typologically unique, bidirectional system with two distinct and productive processes: anticipatory [+ATR] spreads leftward to non-high vowels and progressive [−ATR] spreads rightward to high vowels. In this study, we investigated the acoustic correlates of the [ATR] feature in Komo using recordings from twelve native speakers collected in the field. Our aims were to describe the acoustic signature of the feature, evaluate acoustic evidence for the claim that both assimilatory processes indeed involve [ATR] spreading, and explore individual variability in the realization of the feature. The results of linear mixed-effects models indicated that, in both processes, [+ATR] vowels featured lower F1 values, less periodicity, and a relatively pronounced first harmonic. The anticipatory process was also cued by duration differences while the progressive harmony featured a partial difference in spectral slope. As for individual strategies, random forest analysis revealed a great deal of variability in the relative importance of different correlates. While F1 dominated many of the acoustic profiles, some speakers relied primarily on voice quality or duration to signal the feature.},
	journal = {Journal of Phonetics},
	author = {Olejarczuk, Paul and Otero, Manuel A. and Baese-Berk, Melissa M.},
	year = {2019},
	keywords = {[ATR] acoustics, Advanced tongue root harmony, Individual differences, Koman, Random forests},
	pages = {18--41},
}

@misc{boersma_praat_2009,
	title = {Praat: doing phonetics by computer ({Version} 5.1.13)},
	url = {http://www.praat.org},
	author = {Boersma, Paul and Weenink, David},
	year = {2009},
	keywords = {imported},
}

@article{bates_fitting_2015,
	title = {Fitting {Linear} {Mixed}-{Effects} {Models} {Using} lme4},
	volume = {67},
	doi = {10.18637/jss.v067.i01},
	number = {1},
	journal = {Journal of Statistical Software},
	author = {Bates, Douglas and Mächler, Martin and Bolker, Ben and Walker, Steve},
	year = {2015},
	pages = {1--48},
}

@incollection{archangeli_harmony_2007,
	series = {Cambridge {Handbooks} in {Language} and {Linguistics}},
	title = {Harmony},
	booktitle = {The {Cambridge} {Handbook} of {Phonology}},
	publisher = {Cambridge University Press},
	author = {Archangeli, Diana and Pulleyblank, Douglas},
	editor = {Lacy, Paul deEditor},
	year = {2007},
	doi = {10.1017/CBO9780511486371.016},
	pages = {353--378},
}

@article{archangeli_assamese_2019,
	title = {Assamese vowels and vowel harmony},
	volume = {6},
	url = {https://doi.org/10.1515/jsall-2019-2010},
	doi = {doi:10.1515/jsall-2019-2010},
	number = {2},
	urldate = {2024-01-23},
	journal = {Journal of South Asian Languages and Linguistics},
	author = {Archangeli, Diana B. and Yip, Jonathan},
	year = {2019},
	pages = {151--183},
}

@inproceedings{arjovsky_wasserstein_2017,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Wasserstein {Generative} {Adversarial} {Networks}},
	volume = {70},
	url = {https://proceedings.mlr.press/v70/arjovsky17a.html},
	abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to different distances between distributions.},
	booktitle = {Proceedings of the 34th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Arjovsky, Martin and Chintala, Soumith and Bottou, Léon},
	editor = {Precup, Doina and Teh, Yee Whye},
	month = aug,
	year = {2017},
	pages = {214--223},
}

@inproceedings{wilson_unbounded_2006,
	title = {Unbounded spreading is myopic},
	booktitle = {Current {Perspectives} on {Phonology} workshop, {Phonology} {Fest}},
	author = {Wilson, Colin},
	year = {2006},
}

@article{mintz_infants_2018,
	title = {Infants' sensitivity to vowel harmony and its role in segmenting speech},
	volume = {171},
	issn = {0010-0277},
	url = {https://www.sciencedirect.com/science/article/pii/S0010027717302755},
	doi = {10.1016/j.cognition.2017.10.020},
	abstract = {A critical part of infants’ ability to acquire any language involves segmenting continuous speech input into discrete word forms. Certain properties of words could provide infants with reliable cues to word boundaries. Here we investigate the potential utility of vowel harmony (VH), a phonological property whereby vowels within a word systematically exhibit similarity (“harmony”) for some aspect of the way they are pronounced. We present evidence that infants with no experience of VH in their native language nevertheless actively use these patterns to generate hypotheses about where words begin and end in the speech stream. In two sets of experiments, we exposed infants learning English, a language without VH, to a continuous speech stream in which the only systematic patterns available to be used as cues to word boundaries came from syllable sequences that showed VH or those that showed vowel disharmony (dissimilarity). After hearing less than one minute of the streams, infants showed evidence of sensitivity to VH cues. These results suggest that infants have an experience-independent sensitivity to VH, and are predisposed to segment speech according to harmony patterns. We also found that when the VH patterns were more subtle (Experiment 2), infants required more exposure to the speech stream before they segmented based on VH, consistent with previous work on infants’ preferences relating to processing load. Our findings evidence a previously unknown mechanism by which infants could discover the words of their language, and they shed light on the perceptual mechanisms that might be responsible for the emergence of vowel harmony as an organizing principle for the sound structure of words in many languages.},
	urldate = {2024-03-02},
	journal = {Cognition},
	author = {Mintz, Toben H. and Walker, Rachel L. and Welday, Ashlee and Kidd, Celeste},
	month = feb,
	year = {2018},
	keywords = {Infants, Language acquisition, Learning biases, Speech processing, Vowel harmony, Word segmentation},
	pages = {95--107},
	file = {Accepted Version:files/581/Mintz et al. - 2018 - Infants' sensitivity to vowel harmony and its role.pdf:application/pdf},
}

@incollection{census_2011,
    author = {Government General of India},
    title = {Census of India},
    institution = {Government of India},
    year = {2011}
}

@inproceedings{ohala94b_icslp,
  author={John J. Ohala},
  title={{Towards a universal, phonetically-based, theory of vowel harmony}},
  year=1994,
  booktitle=icslp,
  pages={491--494},
  doi={10.21437/ICSLP.1994-113}
}

@article{rose2011harmony,
  title={Harmony systems},
  author={Rose, Sharon and Walker, Rachel},
  journal={The handbook of phonological theory},
  pages={240--290},
  year={2011},
  publisher={Wiley Online Library}
}

@book{blevins2004evolutionary,
  title={Evolutionary phonology: The emergence of sound patterns},
  author={Blevins, Juliette},
  year={2004},
  publisher={Cambridge University Press}
}